{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8915f21e",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0f880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8788, 59)\n",
      "Date range: 2020-03-01 00:00:00 to 2024-06-01 00:00:00\n",
      "\n",
      "Target distribution:\n",
      "0.0    8441\n",
      "1.0     347\n",
      "Name: Layoff_Event_Binary, dtype: int64\n",
      "Class balance: 0.0395\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/layoffs_modeling_ready.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"\\nTarget distribution:\\n{df['Layoff_Event_Binary'].value_counts()}\")\n",
    "print(f\"Class balance: {df['Layoff_Event_Binary'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b73dda6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "      <th>layoff_event_lag1</th>\n",
       "      <th>Layoff_Event_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>amazon</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company       Date  layoff_event_lag1  Layoff_Event_Binary\n",
       "490  amazon 2022-01-01                0.0                  0.0\n",
       "491  amazon 2022-02-01                0.0                  0.0\n",
       "492  amazon 2022-03-01                0.0                  0.0\n",
       "493  amazon 2022-04-01                0.0                  0.0\n",
       "494  amazon 2022-05-01                0.0                  0.0\n",
       "495  amazon 2022-06-01                0.0                  0.0\n",
       "496  amazon 2022-07-01                0.0                  0.0\n",
       "497  amazon 2022-08-01                0.0                  0.0\n",
       "498  amazon 2022-09-01                0.0                  0.0\n",
       "499  amazon 2022-10-01                0.0                  1.0\n",
       "500  amazon 2022-11-01                1.0                  1.0\n",
       "501  amazon 2022-12-01                1.0                  0.0\n",
       "502  amazon 2023-01-01                0.0                  1.0\n",
       "503  amazon 2023-02-01                1.0                  0.0\n",
       "504  amazon 2023-03-01                0.0                  1.0\n",
       "505  amazon 2023-04-01                1.0                  0.0\n",
       "506  amazon 2023-05-01                0.0                  0.0\n",
       "507  amazon 2023-06-01                0.0                  0.0\n",
       "508  amazon 2023-07-01                0.0                  1.0\n",
       "509  amazon 2023-08-01                1.0                  0.0\n",
       "510  amazon 2023-09-01                0.0                  0.0\n",
       "511  amazon 2023-10-01                0.0                  0.0\n",
       "512  amazon 2023-11-01                0.0                  1.0\n",
       "513  amazon 2023-12-01                1.0                  0.0\n",
       "514  amazon 2024-01-01                0.0                  1.0\n",
       "515  amazon 2024-02-01                1.0                  1.0\n",
       "516  amazon 2024-03-01                1.0                  0.0\n",
       "517  amazon 2024-04-01                0.0                  1.0\n",
       "518  amazon 2024-05-01                1.0                  0.0\n",
       "519  amazon 2024-06-01                0.0                  0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Company'] == 'amazon'][['Company', 'Date', 'layoff_event_lag1','Layoff_Event_Binary']].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13fc8630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8443\n",
       "1.0     345\n",
       "Name: layoff_event_lag1, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['layoff_event_lag1'].describe()\n",
    "df['layoff_event_lag1'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901f8d5",
   "metadata": {},
   "source": [
    "## Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ea3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features: 55\n",
      "X shape: (8788, 55)\n",
      "y shape: (8788,)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['Company', 'Date', 'Latest_Country', 'Layoff_Event_Binary']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Layoff_Event_Binary']\n",
    "\n",
    "print(f\"Final features: {len(feature_cols)}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Missing values: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac6baa",
   "metadata": {},
   "source": [
    "## Temporal Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa94f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split date: 2023-06-01\n",
      "\n",
      "Train set:\n",
      "  Size: 6591\n",
      "  Positive class: 218.0 (0.0331)\n",
      "  Date range: 2020-03-01 to 2023-05-01\n",
      "\n",
      "Test set:\n",
      "  Size: 2197\n",
      "  Positive class: 129.0 (0.0587)\n",
      "  Date range: 2023-06-01 to 2024-06-01\n"
     ]
    }
   ],
   "source": [
    "split_date = '2023-06-01'\n",
    "\n",
    "train_mask = df['Date'] < split_date\n",
    "test_mask = df['Date'] >= split_date\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "print(f\"Split date: {split_date}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Size: {len(X_train)}\")\n",
    "print(f\"  Positive class: {y_train.sum()} ({y_train.mean():.4f})\")\n",
    "print(f\"  Date range: {df[train_mask]['Date'].min().date()} to {df[train_mask]['Date'].max().date()}\")\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Size: {len(X_test)}\")\n",
    "print(f\"  Positive class: {y_test.sum()} ({y_test.mean():.4f})\")\n",
    "print(f\"  Date range: {df[test_mask]['Date'].min().date()} to {df[test_mask]['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc3397",
   "metadata": {},
   "source": [
    "## Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cce6a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous features to scale: 29\n",
      "Binary features (no scaling): 26\n",
      "\n",
      "Scaled train shape: (6591, 55)\n",
      "Scaled test shape: (2197, 55)\n",
      "Train mean: 0.076137\n",
      "Train std: 0.773054\n"
     ]
    }
   ],
   "source": [
    "continuous_features = [col for col in feature_cols if not col.startswith(('Industry_', 'Stage_', 'negative_', 'declining_')) and col != 'layoff_event_lag1']\n",
    "binary_features = [col for col in feature_cols if col.startswith(('Industry_', 'Stage_', 'negative_', 'declining_')) or col == 'layoff_event_lag1']\n",
    "\n",
    "print(f\"Continuous features to scale: {len(continuous_features)}\")\n",
    "print(f\"Binary features (no scaling): {len(binary_features)}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_continuous = scaler.fit_transform(X_train[continuous_features])\n",
    "X_test_continuous = scaler.transform(X_test[continuous_features])\n",
    "\n",
    "X_train_scaled = np.hstack([X_train_continuous, X_train[binary_features].values])\n",
    "X_test_scaled = np.hstack([X_test_continuous, X_test[binary_features].values])\n",
    "\n",
    "print(f\"\\nScaled train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test shape: {X_test_scaled.shape}\")\n",
    "print(f\"Train mean: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Train std: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db8951",
   "metadata": {},
   "source": [
    "## Baseline - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55609091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "  Train Accuracy: 0.9848\n",
      "  Test Accuracy: 0.9536\n",
      "  Test F1-Score: 0.3462\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[2068    0]\n",
      " [ 102   27]]\n",
      "\n",
      "Feature Importances (non-zero only):\n",
      "  months_since_last_layoff: 0.765187\n",
      "  Latest_Funds_Raised_Log: 0.134756\n",
      "  avg_jobless_claims_lag1: 0.018276\n",
      "  current_ratio_lag1: 0.012266\n",
      "  fed_funds_rate_lag1: 0.012053\n",
      "  debt_to_equity_lag1: 0.011560\n",
      "  roa_lag1: 0.008212\n",
      "  stockholders_equity_growth_yoy: 0.006820\n",
      "  sp500_change_6mo_lag1: 0.006156\n",
      "  debt_to_assets_change_yoy: 0.004962\n",
      "  roe_lag1: 0.004753\n",
      "  Industry_Hardware: 0.004157\n",
      "  current_assets_growth_yoy: 0.004090\n",
      "  current_liabilities_growth_yoy: 0.002346\n",
      "  operating_income_growth_yoy: 0.002315\n",
      "  rd_to_assets_lag1: 0.001165\n",
      "  inflation_rate_yoy_lag1: 0.000476\n",
      "  Industry_Infrastructure: 0.000307\n",
      "  unemployment_income_interaction: 0.000143\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=50, min_samples_leaf=20)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_dt = dt_model.predict(X_train_scaled)\n",
    "y_test_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "train_acc_dt = accuracy_score(y_train, y_train_pred_dt)\n",
    "test_acc_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "test_f1_dt = f1_score(y_test, y_test_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"  Train Accuracy: {train_acc_dt:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc_dt:.4f}\")\n",
    "print(f\"  Test F1-Score: {test_f1_dt:.4f}\")\n",
    "print(f\"\\nTest Confusion Matrix:\")\n",
    "cm_dt = confusion_matrix(y_test, y_test_pred_dt)\n",
    "print(cm_dt)\n",
    "\n",
    "print(f\"\\nFeature Importances (non-zero only):\")\n",
    "feature_names = continuous_features + binary_features\n",
    "importances_dt = dt_model.feature_importances_\n",
    "non_zero_idx = np.where(importances_dt > 0)[0]\n",
    "sorted_idx = non_zero_idx[np.argsort(importances_dt[non_zero_idx])[::-1]]\n",
    "\n",
    "for idx in sorted_idx:\n",
    "    print(f\"  {feature_names[idx]}: {importances_dt[idx]:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7374_A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
